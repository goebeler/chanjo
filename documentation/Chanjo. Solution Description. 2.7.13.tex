\documentclass[pdftex,a4paper,11pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{verbatim}
\usepackage{amsthm} 
\usepackage{amsmath}
\usepackage{here}
\usepackage{epstopdf}
\usepackage{algorithm}
\usepackage{algorithmic}

%opening
\title{Advanced topics in Machine Learning. \\ Concept of the solution of the programming assignment}
\author{ Team Chanjo. \\ Johannes Jendersie, Anton Niadzelka }

\begin{document}

\maketitle

\section{Challenge decription}
The challenge’s objective is easily described: Create a recommender system for first names! Given a set of names for which a user has shown interest in, the recommender should provide suggestions for further names for that user. The recommender’s quality will be assessed on an evaluation data set. Thus, the task can be considered a standard item recommendation task.

\section{Solution}

We received data about user activities from nameling.net website. Data consists of 515,848 activities made by 60,922 users. Our idea was to assign to each activity corresponding rating. The most explicit user expression will be ranked higher. We thought that \textit{ENTER SEARCH} will receive the highest rank, as  the evaluation is restricted only to this activity and all other activities are biased towards the lists of names which were displayed. However, using our evaluation measure we obtained better results when the highest rating was assigned to \textit{ADD FAVORITE} action. 


After initialization we obtained a matrix which contains for each user-name-pair either the user's rating for the name or nothing. It is not possible to store the whole matrix (12 GB) on a usual laptop RAM, as the number of user names is too high. Moreover, the matrix is sparse as we have less than 10 activities in average pro user. So, we stored only existing ratings for each user with the index number of the corresponding name.

The recommendation approach, that we are going to use, is based on a model (\ref{1}) described in a paper \cite{2}. 

\begin{equation} \label{1} \hat{r}_{u i} = \mu + b_u + b_i + p^T _u q_i   \text{, where} \end{equation}
\begin{center} $  \mu \text{ - average over all table  ,}  $ \end{center}
\begin{center} $ b_u $ and $ b_i $ indicate the observed deviations of user u and item i, respectively, from the average.
 \end{center}
\begin{center} For a given item i, the elements of $ q_i $ measure the extent \\ to which the item possesses those factors, positive or negative. \end{center}
\begin{center} The elements of $ p_u $ measure attitude of the user \\ to latent factors. \end{center}

Factors mentioned above are obtained by using singular value decomposition(SVD) of the initial matrix, as SVD maps both users and items to a joint latent factor space of dimensionality $ f $. As it stated in book \cite{1} the latent space tries to explain ratings by characterizing both products and users on factors automatically inferred from user feedback. Usual SVD algorithms are not easily applicable in our case, as we have a really huge sparse matrix. So, we are going to use the algorithm described in \cite{2} in chapter 4.3. 

\subsection{Learning}

The values $p_u$ and $q_i$ have to be learned after the initialization. The following pseudo code describes the algorithm described in \cite{2} in chapter 4.3.

\begin{algorithm}
\caption{LearnNextLatentFactor(f)}
\begin{algorithmic}
\FORALL { $r_{ui} \in RatingMatrix$ }
\STATE $support \leftarrow min(\#UserRatings, \#ItemRatings)$
\STATE $error_{ui} \leftarrow support \cdot (r_{ui} - p_u^T \cdot q_i) / (support + SHRINKAGE \cdot f)$
\ENDFOR
\STATE $oldError \leftarrow \sum_{r_{ui} \in RatingMatrix} (r_{ui} - p_u^T \cdot q_i)^2 $
\STATE $newError \leftarrow 0$
\FORALL {$q_i$}
\STATE $q_i[f] \leftarrow 1$
\ENDFOR
\WHILE {$newError/oldError < 1-EPSILON$}
\STATE $p_u[f] \leftarrow p_u[f]+\frac{\sum_{i \in Ratings(u)} r_{ui} \cdot q_i[f]}{\sum_{i \in Ratings(u)} q_i[f]^2}$
\STATE $q_i[f] \leftarrow q_i[f]+\frac{\sum_{u \in Rated(i)} r_{ui} \cdot p_u[f]}{\sum_{u \in Rated(i)} p_u[f]^2}$
\STATE $oldError \leftarrow newError$
\STATE $newError \leftarrow \sum_{r_{ui} \in RatingMatrix} (r_{ui} - p_u^T \cdot q_i)^2$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Learn()}
\begin{algorithmic}
\STATE $p_u \leftarrow 0$
\STATE $q_i \leftarrow 0$
\FOR {$f \in [0,NUM\_FACTORS]$}
\STATE LearnNextLatentFactor(f)
\ENDFOR
\end{algorithmic}
\end{algorithm}



\section{Evaluation}

The quality of the result was measured by the root mean squared error (RMSE) (\ref{2}).
 
\begin{equation} \label{2} \sqrt{ \sum_{(u,i) \in TestSet} (r_{u i} - \hat{r}_{u i} ) ^2 / \left| TestSet \right| } \end{equation}

We have 8 parameters that could be tuned. These are 5 initial ratings for each action, the number of latent factors $ f $, the shrinkage and the epsilon parameter. For that we cross validated our model with different values of these parameters and afterwards have chosen the one with the best result. To build test sets for the cross validation some actions of some users were removed before learning. Due to the other actions the user is still known to the learner and could be characterized.

\section{Result}
The parameters listed below have had the smallest RMSE = 0.392 during our test phase.

Ratings:\\
\begin{align*}
LINK SEARCH &= 0.05\\
ENTER SEARCH &= 0.2\\
LINK CATEGORY SEARCH &= 0.05\\
NAME DETAILS &= 0.1\\
ADD FAVORITE &= 0.6\\
NUM_FACTORS &= 40\\
SHRINKAGE &= 3.9\\
EPSILON &= 0.0001
\end{align*}



\begin{thebibliography}{99}
\bibitem{1} Recommender Systems Handbook by Ricci, F.; Rokach, L.; Shapira, B.; Kantor, P.B. 2011, XXIX, Springer,  Chapter 5
\bibitem{2}  Modeling Relationships at Multiple Scales to Im-prove Accuracy of Large Recommender Systems, Bell, R.M., Koren, Y., and Volinsky, C., Proc. 13th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, 2007.
\end{thebibliography}
\nocite{*}
\bibliographystyle{cell}
\bibliography{literature}

\end{document}