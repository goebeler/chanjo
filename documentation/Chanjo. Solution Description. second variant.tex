\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{verbatim}
\usepackage{amsthm} 
\usepackage{amsmath}

%opening
\title{Advanced topics in Machine Learning. \\ Concept of the solution of the programming assignment}
\author{ Team Chanjo. \\ Johannes Jendersie, Anton Niadzelka }

\begin{document}

\maketitle

\section{Challenge decription}
The challenge’s objective is easily described: Create a recommender system for first names! Given a set of names for which a user has shown interest in, the recommender should provide suggestions for further names for that user. The recommender’s quality will be assessed on an evaluation data set. Thus, the task can be considered a standard item recommendation task.

\section{Solution}

We received data about user activities from nameling.net website. Data consists of 515,848 activities made by 60,922 users. Our idea is to assign to each activity corresponding rating. The most explicit user expression will be ranked higher. \textit{ENTER SEARCH} will receive the highest rank, as  the evaluation is restricted only to this activity and all other activities are biased towards the lists of names which were displayed. 


So, afterwards we will get a table where for each name we will have some user rating or nothing. It is not possible to store RAM on usual laptop whole table, as the number of user names is too high. Moreover, the table is sparse as we have less than 10 activities in average pro user. So, we store for each user only existing ratings with index number of the corresponding name.

Recommendation approach, that we are going to use, is based on a model (\ref{1}) described in a paper \cite{2}. 

\begin{equation} \label{1} \hat{r}_{u i} = \mu + b_u + b_i + p^T _u q_i   \text{, where} \end{equation}
\begin{center} $  \mu \text{ - average over all table  ,}  $ \end{center}
\begin{center} $ b_u $ and $ b_i $ indicate the observed deviations of user u and item i, respectively, from the average.
 \end{center}
\begin{center} For a given item i, the elements of $ q_i $ measure the extent \\ to which the item possesses those factors, positive or negative. \end{center}
\begin{center} The elements of $ p_u $ measure attitude of the user \\ to latent factors. \end{center}

Factors mentioned above obtain using singular value decomposition(SVD) of an initial matix, as SVD maps both users and items to a joint latent factor space of dimensionality $ f $. As it stated in book \cite{1} the latent space tries to explain ratings by characterizing both products and users on factors automatically inferred from user feedback. Usual SVD algorithms are not easily applicanle in our case, as we have a really huge sparse matrix. So, we are going to use algorithm described in \cite{2} in chapter 4.3. 

\section{Evaluation}

Quality of the result will be measured by the root mean squared error \ref{2}.
 
\begin{equation} \label{2} \sqrt{ \sum_{(u,i) \in TestSet} (r_{u i} - \hat{r}_{u i} ) ^2 / \left| TestSet \right| } \end{equation}

We have a few parameters that have to be tuned. They are initial ratings for each action, number of latent factors $ f $. For that we are going to cross validate our model with different values of these parameters and afterwards choose one with the best result. 

\section{Work Plan}

Johannes Jendersie:

\begin{enumerate}
\item Team work organisation,
\item Program Interface,
\item Sparse Matrix,
\item Recommender Algorithm implementation.
\item Query Interface
\end{enumerate}


Anton Niadzelka:

\begin{enumerate}
\item Idea Description, 
\item Documentation,
\item Evaluation,
\item Performance Measurement implementation,
\item Recommendation creation
\end{enumerate}

\begin{thebibliography}{99}
\bibitem{1} Recommender Systems Handbook by Ricci, F.; Rokach, L.; Shapira, B.; Kantor, P.B. 2011, XXIX, Springer,  Chapter 5
\bibitem{2}  Modeling Relationships at Multiple Scales to Im-prove Accuracy of Large Recommender Systems, Bell, R.M., Koren, Y., and Volinsky, C., Proc. 13th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, 2007.
\end{thebibliography}
\nocite{*}
\bibliographystyle{cell}
\bibliography{literature}

\end{document}